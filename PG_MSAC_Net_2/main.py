"""
PG-MSAC-Netä¸»ç¨‹åº
ç‰©ç†å¼•å¯¼çš„å¤šå°ºåº¦è‡ªé€‚åº”è·¨åŸŸè½´æ‰¿æ•…éšœè¯Šæ–­ç½‘ç»œ
"""

import os
import sys
import time
import random
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
import warnings
from typing import Dict, Any, Optional

warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from config import config, update_config_from_args
from models.PG_MSAC_Net import PG_MSAC_Net
from datasets.JNU_bearing_dataset import create_jnu_dataloaders, create_single_domain_dataloader
from training.trainer import PGMSACTrainer
from evaluation.evaluator import ModelEvaluator
from utils.visualization import plot_training_curves, plot_confusion_matrix_advanced
from utils.checkpoint import CheckpointManager


class PGMSACNetError(Exception):
    """PG-MSAC-Netè‡ªå®šä¹‰å¼‚å¸¸"""
    pass


class DataLoadError(PGMSACNetError):
    """æ•°æ®åŠ è½½å¼‚å¸¸"""
    pass


class ModelError(PGMSACNetError):
    """æ¨¡å‹ç›¸å…³å¼‚å¸¸"""
    pass


def set_seed(seed: int = 42):
    """è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯å¤ç°"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    print(f"Random seed set to {seed}")


def setup_device() -> torch.device:
    """è®¾ç½®è®¡ç®—è®¾å¤‡"""
    device = config.device
    if torch.cuda.is_available():
        print(f"Using GPU: {torch.cuda.get_device_name(device)}")
        print(f"GPU Memory: {torch.cuda.get_device_properties(device).total_memory / 1024 ** 3:.1f} GB")
    else:
        print("CUDA not available, using CPU")
    return device


def check_data_path() -> bool:
    """æ£€æŸ¥æ•°æ®è·¯å¾„æ˜¯å¦å­˜åœ¨"""
    data_path = config.data.data_root
    if not os.path.exists(data_path):
        print(f"âŒ Data path not found: {data_path}")
        print("Please ensure your data is placed in the correct directory or update the path in config.py")
        print(f"Expected structure: {data_path}/JNU_*.mat files")
        return False

    # æ£€æŸ¥æ˜¯å¦æœ‰.matæ–‡ä»¶
    mat_files = [f for f in os.listdir(data_path) if f.endswith('.mat')]
    if not mat_files:
        print(f"âŒ No .mat files found in {data_path}")
        print("Please place your JNU bearing dataset files in the data directory")
        return False

    print(f"âœ… Data path verified: {data_path}")
    print(f"Found {len(mat_files)} .mat files")
    return True


def load_datasets() -> Dict[str, DataLoader]:
    """åŠ è½½æ•°æ®é›†"""
    print("Loading datasets...")

    try:
        # åˆ›å»ºè·¨åŸŸæ•°æ®åŠ è½½å™¨
        dataloaders = create_jnu_dataloaders(
            data_path=config.data.data_root,
            source_speed=config.data.source_speed,
            target_speed=config.data.target_speed,
            source_shot=config.data.source_shot,
            target_shot=config.data.target_shot,
            sample_len=config.data.sample_len,
            batch_size=config.training.batch_size,
            normalize_type=config.data.normalize_type,
            num_workers=config.num_workers,
            fault_types=config.data.class_names
        )

        print(f"âœ… Source train samples: {len(dataloaders['source_train'].dataset)}")
        print(f"âœ… Source test samples: {len(dataloaders['source_test'].dataset)}")
        print(f"âœ… Target samples: {len(dataloaders['target'].dataset)}")

        return dataloaders

    except Exception as e:
        raise DataLoadError(f"Failed to load datasets: {str(e)}")


def create_model() -> PG_MSAC_Net:
    """åˆ›å»ºæ¨¡å‹"""
    print("Creating PG-MSAC-Net model...")

    try:
        model = PG_MSAC_Net(
            num_classes=config.data.num_classes,
            sample_len=config.data.sample_len,
            mpie_config=config.mpie,
            amscnn_config=config.amscnn,
            msgda_config=config.msgda
        )

        model = model.to(config.device)

        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        complexity = model.get_model_complexity()
        total_params = complexity['total_parameters']
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

        print(f"âœ… Model created successfully")
        print(f"Total parameters: {total_params:,}")
        print(f"Trainable parameters: {trainable_params:,}")
        print(f"Model size: {complexity['model_size_mb']:.2f} MB")

        return model

    except Exception as e:
        raise ModelError(f"Failed to create model: {str(e)}")


def create_trainer(model: PG_MSAC_Net, dataloaders: Dict[str, DataLoader]) -> PGMSACTrainer:
    """åˆ›å»ºè®­ç»ƒå™¨"""
    print("Creating trainer...")

    try:
        trainer = PGMSACTrainer(
            model=model,
            config=config,
            device=config.device
        )

        print("âœ… Trainer created successfully")
        return trainer

    except Exception as e:
        raise ModelError(f"Failed to create trainer: {str(e)}")


def run_quick_test() -> bool:
    """è¿è¡Œå¿«é€Ÿæµ‹è¯•ä»¥éªŒè¯ç³»ç»Ÿå·¥ä½œ"""
    print("=" * 60)
    print("Running Quick Test")
    print("=" * 60)

    try:
        # 1. æ£€æŸ¥æ•°æ®è·¯å¾„ï¼ˆä½†ä¸è¦æ±‚æ•°æ®å­˜åœ¨ï¼‰
        print("1. Checking system setup...")
        print(f"   Project root: {os.getcwd()}")
        print(f"   Data path: {config.data.data_root}")
        print(f"   Results path: {config.results_dir}")

        # 2. åˆ›å»ºè™šæ‹Ÿæ•°æ®é›†è¿›è¡Œæµ‹è¯•
        print("2. Creating dummy datasets for testing...")
        from datasets.data_utils import BaseDataset

        # ç”Ÿæˆè™šæ‹Ÿæ•°æ®
        dummy_data = np.random.randn(20, 1, config.data.sample_len)
        dummy_labels = np.random.randint(0, config.data.num_classes, 20)

        dummy_dataset = BaseDataset(dummy_data, dummy_labels)
        dummy_loader = DataLoader(dummy_dataset, batch_size=4, shuffle=False)

        dataloaders = {
            'source_train': dummy_loader,
            'source_test': dummy_loader,
            'target': dummy_loader
        }
        print("âœ… Dummy datasets created")

        # 3. æµ‹è¯•æ¨¡å‹åˆ›å»º
        print("3. Testing model creation...")
        model = create_model()
        print("âœ… Model creation successful")

        # 4. æµ‹è¯•å‰å‘ä¼ æ’­
        print("4. Testing forward pass...")
        model.eval()
        with torch.no_grad():
            for data, labels in dummy_loader:
                data = data.to(config.device)
                output = model(data)
                expected_shape = (data.shape[0], config.data.num_classes)
                assert output.shape == expected_shape, f"Expected {expected_shape}, got {output.shape}"
                print(f"âœ… Forward pass successful. Input: {data.shape}, Output: {output.shape}")
                break

        # 5. æµ‹è¯•ç‰¹å¾æå–
        print("5. Testing feature extraction...")
        features = model.extract_features(data)
        print(f"âœ… Feature extraction successful. Features: {list(features.keys())}")

        # 6. æµ‹è¯•è®­ç»ƒå™¨åˆ›å»º
        print("6. Testing trainer creation...")
        trainer = create_trainer(model, dataloaders)
        model_info = trainer.get_model_info()
        print(f"âœ… Trainer creation successful. Model: {model_info['model_name']}")

        print("\n" + "=" * 60)
        print("ğŸ‰ All quick tests passed! System is ready for use.")
        print("\nTo run with real data:")
        print("1. Place your JNU bearing dataset in:", config.data.data_root)
        print("2. Run: python main.py --experiment_type cross_domain")
        print("=" * 60)

        return True

    except Exception as e:
        print(f"\nâŒ Quick test failed: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def run_single_experiment() -> Optional[Dict[str, Any]]:
    """è¿è¡Œå•æ¬¡å®éªŒ"""
    print("=" * 60)
    print("Running Single Experiment")
    print("=" * 60)

    try:
        # æ£€æŸ¥æ•°æ®è·¯å¾„
        if not check_data_path():
            print("Please fix data path issues and try again.")
            return None

        # åŠ è½½æ•°æ®
        dataloaders = load_datasets()

        # åˆ›å»ºæ¨¡å‹
        model = create_model()

        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = create_trainer(model, dataloaders)

        # è®­ç»ƒæ¨¡å‹
        print("\nStarting training...")
        start_time = time.time()

        trainer.fit(
            train_loader=dataloaders['source_train'],
            val_loader=dataloaders['source_test'],
            target_loader=dataloaders['target'] if config.training.domain_adaptation else None
        )

        training_time = time.time() - start_time
        print(f"Training completed in {training_time:.2f} seconds")

        # è¯„ä¼°æ¨¡å‹
        print("\nEvaluating model...")
        test_results = trainer.cross_domain_evaluate(
            source_loader=dataloaders['source_test'],
            target_loader=dataloaders['target']
        )

        # ä¿å­˜æœ€ç»ˆç»“æœ
        final_results = {
            'source_accuracy': test_results['source']['accuracy'],
            'target_accuracy': test_results['target']['accuracy'],
            'domain_gap': test_results['domain_gap'],
            'transfer_ratio': test_results['transfer_ratio'],
            'training_time': training_time,
            'model_params': sum(p.numel() for p in model.parameters()),
            'config': config.get_experiment_name()
        }

        print(f"\nğŸ‰ Final Results:")
        print(f"Source Accuracy: {final_results['source_accuracy']:.4f}")
        print(f"Target Accuracy: {final_results['target_accuracy']:.4f}")
        print(f"Domain Gap: {final_results['domain_gap']:.4f}")
        print(f"Transfer Ratio: {final_results['transfer_ratio']:.4f}")

        return final_results

    except Exception as e:
        print(f"âŒ Experiment failed: {str(e)}")
        import traceback
        traceback.print_exc()
        return None


def run_multiple_trials(num_trials: int = 5) -> Optional[Dict[str, Any]]:
    """è¿è¡Œå¤šæ¬¡å®éªŒè·å–ç¨³å®šç»“æœ"""
    print("=" * 60)
    print(f"Running Multiple Trials (n={num_trials})")
    print("=" * 60)

    if not check_data_path():
        print("Please fix data path issues and try again.")
        return None

    all_results = []

    for trial in range(num_trials):
        print(f"\n--- Trial {trial + 1}/{num_trials} ---")

        # è®¾ç½®ä¸åŒçš„éšæœºç§å­
        set_seed(config.seed + trial)

        try:
            results = run_single_experiment()
            if results is not None:
                results['trial'] = trial + 1
                all_results.append(results)
                print(f"Trial {trial + 1} - Target Accuracy: {results['target_accuracy']:.4f}")
            else:
                print(f"Trial {trial + 1} failed")

        except Exception as e:
            print(f"Trial {trial + 1} failed: {str(e)}")
            continue

    # è®¡ç®—ç»Ÿè®¡ç»“æœ
    if all_results:
        target_accuracies = [r['target_accuracy'] for r in all_results]
        source_accuracies = [r['source_accuracy'] for r in all_results]

        stats = {
            'mean_source_accuracy': np.mean(source_accuracies),
            'std_source_accuracy': np.std(source_accuracies),
            'mean_target_accuracy': np.mean(target_accuracies),
            'std_target_accuracy': np.std(target_accuracies),
            'num_trials': len(all_results)
        }

        print("\n" + "=" * 60)
        print("ğŸ‰ FINAL RESULTS")
        print("=" * 60)
        print(f"Mean Source Accuracy: {stats['mean_source_accuracy']:.4f} Â± {stats['std_source_accuracy']:.4f}")
        print(f"Mean Target Accuracy: {stats['mean_target_accuracy']:.4f} Â± {stats['std_target_accuracy']:.4f}")
        print(f"Successful trials: {stats['num_trials']}/{num_trials}")

        # ä¿å­˜ç»Ÿè®¡ç»“æœ
        results_path = os.path.join(config.results_dir, 'final_results.npz')
        np.savez(results_path, stats=stats, all_results=all_results)
        print(f"Results saved to: {results_path}")

        return stats
    else:
        print("âŒ All trials failed!")
        return None


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ PG-MSAC-Net: Physical-Guided Multi-Scale Adaptive Cross-Domain Network")
    print("for Bearing Fault Diagnosis")
    print("=" * 80)

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    try:
        args = update_config_from_args()
        experiment_type = args.experiment_type
    except SystemExit:
        # å¦‚æœæ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®
        experiment_type = 'quick_test'

    # è®¾ç½®éšæœºç§å­
    set_seed(config.seed)

    # è®¾ç½®è®¾å¤‡
    device = setup_device()

    # æ‰“å°é…ç½®ä¿¡æ¯
    config.print_config()

    # åˆ›å»ºç»“æœä¿å­˜ç›®å½•
    os.makedirs(config.experiment_dir, exist_ok=True)

    try:
        if experiment_type == 'quick_test':
            # è¿è¡Œå¿«é€Ÿæµ‹è¯•
            print("\nğŸ”§ Running Quick Test...")
            success = run_quick_test()
            if success:
                print("\nâœ… System check passed! You can now run full experiments.")
                print("\nNext steps:")
                print("â€¢ Place JNU dataset in:", config.data.data_root)
                print("â€¢ Run full training: python main.py --experiment_type cross_domain")
                return 0
            else:
                print("\nâŒ System check failed. Please fix the issues above.")
                return 1

        elif experiment_type == 'cross_domain':
            # è¿è¡Œè·¨åŸŸå®éªŒ
            print("\nğŸš€ Running Cross-Domain Experiment...")
            results = run_multiple_trials(num_trials=3)
            if results:
                print("\nâœ… Cross-domain experiment completed successfully!")
            else:
                print("\nâŒ Cross-domain experiment failed.")
                return 1

        elif experiment_type == 'single':
            # è¿è¡Œå•æ¬¡å®éªŒ
            print("\nğŸš€ Running Single Experiment...")
            results = run_single_experiment()
            if results:
                print("\nâœ… Single experiment completed successfully!")
            else:
                print("\nâŒ Single experiment failed.")
                return 1

        else:
            print(f"âŒ Unknown experiment type: {experiment_type}")
            print("Available types: quick_test, cross_domain, single")
            return 1

        print("\nğŸ‰ Experiment completed!")
        return 0

    except KeyboardInterrupt:
        print("\nâš ï¸ Experiment interrupted by user.")
        return 1

    except Exception as e:
        print(f"\nâŒ Experiment failed with error: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    exit(main())