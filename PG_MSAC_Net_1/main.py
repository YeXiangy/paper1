"""
PG-MSAC-Netä¸»ç¨‹åº
ç‰©ç†å¼•å¯¼çš„å¤šå°ºåº¦è‡ªé€‚åº”è·¨åŸŸè½´æ‰¿æ•…éšœè¯Šæ–­ç½‘ç»œ
"""

import os
import sys
import time
import random
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
import warnings

warnings.filterwarnings('ignore')

# å¯¼å…¥é¡¹ç›®æ¨¡å— - ä¿®å¤åçš„å¯¼å…¥
from config import config, update_config_from_args
from models.PG_MSAC_Net import PG_MSAC_Net
from datasets.JNU_bearing_dataset import create_jnu_dataloaders, create_single_domain_dataloader
from training.trainer import PGMSACTrainer
from evaluation.evaluator import ModelEvaluator
from utils.visualization import plot_training_curves, plot_confusion_matrix_advanced
from utils.checkpoint import CheckpointManager


def set_seed(seed=42):
    """è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯å¤ç°"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def setup_device():
    """è®¾ç½®è®¡ç®—è®¾å¤‡"""
    device = config.device
    if torch.cuda.is_available():
        print(f"Using GPU: {torch.cuda.get_device_name(device)}")
        print(f"GPU Memory: {torch.cuda.get_device_properties(device).total_memory / 1024 ** 3:.1f} GB")
    else:
        print("CUDA not available, using CPU")
    return device


def load_datasets():
    """åŠ è½½æ•°æ®é›†"""
    print("Loading datasets...")

    # åˆ›å»ºè·¨åŸŸæ•°æ®åŠ è½½å™¨
    dataloaders = create_jnu_dataloaders(
        data_path=config.data.data_root,
        source_speed=config.data.source_speed,
        target_speed=config.data.target_speed,
        source_shot=config.data.source_shot,
        target_shot=config.data.target_shot,
        sample_len=config.data.sample_len,
        batch_size=config.training.batch_size,
        normalize_type=config.data.normalize_type,
        num_workers=config.num_workers,
        fault_types=config.data.class_names
    )

    print(f"Source train samples: {len(dataloaders['source_train'].dataset)}")
    print(f"Source test samples: {len(dataloaders['source_test'].dataset)}")
    print(f"Target samples: {len(dataloaders['target'].dataset)}")

    return dataloaders


def create_model():
    """åˆ›å»ºæ¨¡å‹"""
    print("Creating PG-MSAC-Net model...")

    model = PG_MSAC_Net(
        num_classes=config.data.num_classes,
        sample_len=config.data.sample_len,
        mpie_config=config.mpie,
        amscnn_config=config.amscnn,
        msgda_config=config.msgda
    )

    model = model.to(config.device)

    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    print(f"Total parameters: {total_params:,}")
    print(f"Trainable parameters: {trainable_params:,}")
    print(f"Model size: {total_params * 4 / 1024 ** 2:.2f} MB")

    return model


def create_trainer(model, dataloaders):
    """åˆ›å»ºè®­ç»ƒå™¨"""
    print("Creating trainer...")

    trainer = PGMSACTrainer(
        model=model,
        config=config,
        device=config.device
    )

    return trainer


def run_single_experiment():
    """è¿è¡Œå•æ¬¡å®éªŒ"""
    print("=" * 60)
    print("Running Single Experiment")
    print("=" * 60)

    # åŠ è½½æ•°æ®
    dataloaders = load_datasets()

    # åˆ›å»ºæ¨¡å‹
    model = create_model()

    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = create_trainer(model, dataloaders)

    # è®­ç»ƒæ¨¡å‹
    print("\nStarting training...")
    start_time = time.time()

    try:
        trainer.fit(
            train_loader=dataloaders['source_train'],
            val_loader=dataloaders['source_test'],
            target_loader=dataloaders['target'] if config.training.domain_adaptation else None
        )
    except Exception as e:
        print(f"Training failed: {str(e)}")
        return None

    training_time = time.time() - start_time
    print(f"Training completed in {training_time:.2f} seconds")

    # è¯„ä¼°æ¨¡å‹
    print("\nEvaluating model...")
    try:
        # è·¨åŸŸè¯„ä¼°
        test_results = trainer.cross_domain_evaluate(
            source_loader=dataloaders['source_test'],
            target_loader=dataloaders['target']
        )

        # ä¿å­˜æœ€ç»ˆç»“æœ
        final_results = {
            'source_accuracy': test_results['source']['accuracy'],
            'target_accuracy': test_results['target']['accuracy'],
            'domain_gap': test_results['domain_gap'],
            'transfer_ratio': test_results['transfer_ratio'],
            'training_time': training_time,
            'model_params': sum(p.numel() for p in model.parameters()),
            'config': config.get_experiment_name()
        }

        print(f"\nFinal Results:")
        print(f"Source Accuracy: {final_results['source_accuracy']:.4f}")
        print(f"Target Accuracy: {final_results['target_accuracy']:.4f}")
        print(f"Domain Gap: {final_results['domain_gap']:.4f}")
        print(f"Transfer Ratio: {final_results['transfer_ratio']:.4f}")

        return final_results

    except Exception as e:
        print(f"Evaluation failed: {str(e)}")
        return None


def run_multiple_trials(num_trials=5):
    """è¿è¡Œå¤šæ¬¡å®éªŒè·å–ç¨³å®šç»“æœ"""
    print("=" * 60)
    print(f"Running Multiple Trials (n={num_trials})")
    print("=" * 60)

    all_results = []

    for trial in range(num_trials):
        print(f"\n--- Trial {trial + 1}/{num_trials} ---")

        # è®¾ç½®ä¸åŒçš„éšæœºç§å­
        set_seed(config.seed + trial)

        try:
            results = run_single_experiment()
            if results is not None:
                results['trial'] = trial + 1
                all_results.append(results)
                print(f"Trial {trial + 1} - Target Accuracy: {results['target_accuracy']:.4f}")
            else:
                print(f"Trial {trial + 1} failed")

        except Exception as e:
            print(f"Trial {trial + 1} failed: {str(e)}")
            continue

    # è®¡ç®—ç»Ÿè®¡ç»“æœ
    if all_results:
        target_accuracies = [r['target_accuracy'] for r in all_results]
        source_accuracies = [r['source_accuracy'] for r in all_results]

        stats = {
            'mean_source_accuracy': np.mean(source_accuracies),
            'std_source_accuracy': np.std(source_accuracies),
            'mean_target_accuracy': np.mean(target_accuracies),
            'std_target_accuracy': np.std(target_accuracies),
            'num_trials': len(all_results)
        }

        print("\n" + "=" * 60)
        print("FINAL RESULTS")
        print("=" * 60)
        print(f"Mean Source Accuracy: {stats['mean_source_accuracy']:.4f} Â± {stats['std_source_accuracy']:.4f}")
        print(f"Mean Target Accuracy: {stats['mean_target_accuracy']:.4f} Â± {stats['std_target_accuracy']:.4f}")
        print(f"Successful trials: {stats['num_trials']}/{num_trials}")

        # ä¿å­˜ç»Ÿè®¡ç»“æœ
        results_path = os.path.join(config.results_dir, 'final_results.npz')
        np.savez(results_path, stats=stats, all_results=all_results)
        print(f"Results saved to: {results_path}")

        return stats
    else:
        print("All trials failed!")
        return None


def run_quick_test():
    """è¿è¡Œå¿«é€Ÿæµ‹è¯•ä»¥éªŒè¯ç³»ç»Ÿå·¥ä½œ"""
    print("=" * 60)
    print("Running Quick Test")
    print("=" * 60)

    try:
        # æµ‹è¯•æ•°æ®åŠ è½½
        print("Testing data loading...")
        dataloaders = load_datasets()
        print("âœ… Data loading successful")

        # æµ‹è¯•æ¨¡å‹åˆ›å»º
        print("Testing model creation...")
        model = create_model()
        print("âœ… Model creation successful")

        # æµ‹è¯•å‰å‘ä¼ æ’­
        print("Testing forward pass...")
        model.eval()
        with torch.no_grad():
            # ä»æ•°æ®åŠ è½½å™¨è·å–ä¸€ä¸ªæ‰¹æ¬¡
            for data, labels in dataloaders['source_train']:
                output = model(data)
                print(f"âœ… Forward pass successful. Input: {data.shape}, Output: {output.shape}")
                break

        print("\nğŸ‰ All tests passed! System is ready for training.")
        return True

    except Exception as e:
        print(f"âŒ Quick test failed: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("PG-MSAC-Net: Physical-Guided Multi-Scale Adaptive Cross-Domain Network")
    print("for Bearing Fault Diagnosis")
    print("=" * 80)

    # è§£æå‘½ä»¤è¡Œå‚æ•°ï¼ˆå¦‚æœæœ‰ï¼‰
    try:
        args = update_config_from_args()
        experiment_type = args.experiment_type
    except:
        # å¦‚æœæ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®
        experiment_type = 'quick_test'  # é»˜è®¤å…ˆè¿è¡Œå¿«é€Ÿæµ‹è¯•

    # è®¾ç½®éšæœºç§å­
    set_seed(config.seed)

    # è®¾ç½®è®¾å¤‡
    device = setup_device()

    # æ‰“å°é…ç½®ä¿¡æ¯
    config.print_config()

    # åˆ›å»ºç»“æœä¿å­˜ç›®å½•
    os.makedirs(config.experiment_dir, exist_ok=True)

    try:
        if experiment_type == 'quick_test':
            # è¿è¡Œå¿«é€Ÿæµ‹è¯•
            print("\nRunning Quick Test...")
            success = run_quick_test()
            if success:
                print("\nâœ… System check passed! You can now run full experiments.")
                print("Use --experiment_type cross_domain for full training.")
            else:
                print("\nâŒ System check failed. Please fix the issues above.")

        elif experiment_type == 'cross_domain':
            # è¿è¡Œè·¨åŸŸå®éªŒ
            print("\nRunning Cross-Domain Experiment...")
            results = run_multiple_trials(num_trials=3)  # å‡å°‘è¯•éªŒæ¬¡æ•°ç”¨äºæµ‹è¯•

        elif experiment_type == 'single':
            # è¿è¡Œå•æ¬¡å®éªŒ
            print("\nRunning Single Experiment...")
            results = run_single_experiment()

        else:
            print(f"Unknown experiment type: {experiment_type}")
            print("Available types: quick_test, cross_domain, single")

        print("\nExperiment completed!")

    except KeyboardInterrupt:
        print("\nExperiment interrupted by user.")
        sys.exit(1)

    except Exception as e:
        print(f"\nExperiment failed with error: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()